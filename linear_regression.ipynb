{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME: /opt/homebrew/Cellar/openjdk@17/17.0.13/libexec/openjdk.jdk/Contents/Home\n",
      "openjdk version \"17.0.13\" 2024-10-15\n",
      "OpenJDK Runtime Environment Homebrew (build 17.0.13+0)\n",
      "OpenJDK 64-Bit Server VM Homebrew (build 17.0.13+0, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "java_home = subprocess.check_output([\"/usr/libexec/java_home\", \"-v\", \"17\"]).strip().decode('utf-8')\n",
    "\n",
    "# Set JAVA_HOME and PATH\n",
    "os.environ[\"JAVA_HOME\"] = java_home\n",
    "os.environ[\"PATH\"] = os.path.join(java_home, \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local pyspark-shell\"\n",
    "\n",
    "# Verify JAVA_HOME and Java version\n",
    "print(\"JAVA_HOME:\", os.environ['JAVA_HOME'])\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/26 21:56:17 WARN Utils: Your hostname, MacBook-Air-von-Linda.local resolves to a loopback address: 127.0.0.1; using 10.89.101.139 instead (on interface en0)\n",
      "24/11/26 21:56:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/26 21:56:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/26 21:56:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/11/26 21:56:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CBRFSS\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+-------+------+--------+--------+--------+--------+-------+--------+--------+--------+-----+--------+--------+--------+--------+--------+---+\n",
      "|GENHLTH|_AGEG5YR|_RFHYPE6|EMPLOY1|_MICHD|_DRDXAR2|_HCVU653|_RFCHOL3|METVL12_|ALCDAY4|_BMI5CAT|DIFFWALK|_TOTINDA|EDUCA|_INCOMG1|CHCKDNY2|FALL12MN|SMOKE100|CVDINFR4|  y|\n",
      "+-------+--------+--------+-------+------+--------+--------+--------+--------+-------+--------+--------+--------+-----+--------+--------+--------+--------+--------+---+\n",
      "|    4.0|    11.0|     2.0|    1.0|   2.0|     1.0|     9.0|     1.0|   103.0|  888.0|     2.0|     1.0|     1.0|  5.0|     4.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    2.0|     9.0|     1.0|    2.0|   2.0|     2.0|     1.0|     2.0|   106.0|  220.0|     2.0|     2.0|     1.0|  6.0|     5.0|     2.0|     2.0|     2.0|     2.0|  0|\n",
      "|    3.0|     8.0|     1.0|    1.0|   2.0|     2.0|     1.0|     1.0|   104.0|  210.0|     4.0|     2.0|     1.0|  6.0|     5.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    3.0|     9.0|     2.0|    7.0|   2.0|     2.0|     9.0|     2.0|   103.0|  203.0|     3.0|     2.0|     1.0|  6.0|     3.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    1.0|     9.0|     1.0|    2.0|   2.0|     2.0|     1.0|     1.0|   103.0|  202.0|     2.0|     2.0|     1.0|  4.0|     9.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    4.0|    13.0|     2.0|    7.0|   2.0|     1.0|     9.0|     2.0|   104.0|  888.0|     4.0|     1.0|     1.0|  6.0|     2.0|     1.0|    88.0|     1.0|     2.0|  1|\n",
      "|    3.0|     7.0|     2.0|    1.0|   2.0|     2.0|     1.0|     2.0|   103.0|  888.0|     4.0|     1.0|     1.0|  4.0|     2.0|     2.0|    88.0|     1.0|     2.0|  1|\n",
      "|    4.0|    13.0|     2.0|    7.0|   1.0|     2.0|     9.0|     1.0|     2.0|  888.0|     2.0|     2.0|     2.0|  4.0|     3.0|     2.0|     1.0|     2.0|     1.0|  0|\n",
      "|    4.0|    12.0|     2.0|    7.0|   2.0|     1.0|     9.0|     2.0|     2.0|  204.0|     4.0|     1.0|     2.0|  6.0|     9.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    2.0|    12.0|     2.0|    7.0|   2.0|     1.0|     9.0|     2.0|   103.0|  203.0|     4.0|     1.0|     1.0|  6.0|     6.0|     2.0|    88.0|     1.0|     2.0|  1|\n",
      "|    4.0|    13.0|     2.0|    7.0|   1.0|     1.0|     9.0|     2.0|     2.0|  201.0|     4.0|     1.0|     2.0|  5.0|     4.0|     1.0|    88.0|     1.0|     1.0|  0|\n",
      "|    3.0|    10.0|     2.0|    7.0|   2.0|     2.0|     9.0|     2.0|     2.0|  888.0|     3.0|     2.0|     2.0|  5.0|     5.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    3.0|     9.0|     1.0|    1.0|   2.0|     1.0|     1.0|     2.0|     2.0|  203.0|     4.0|     2.0|     2.0|  6.0|     1.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    2.0|    12.0|     2.0|    7.0|   2.0|     2.0|     9.0|     2.0|   104.0|  888.0|     3.0|     2.0|     1.0|  5.0|     1.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    3.0|    11.0|     2.0|    5.0|   2.0|     1.0|     9.0|     1.0|   103.0|  201.0|     2.0|     1.0|     1.0|  2.0|     1.0|     2.0|     3.0|     2.0|     2.0|  0|\n",
      "|    5.0|    11.0|     2.0|    7.0|   2.0|     2.0|     9.0|     1.0|     2.0|  888.0|     4.0|     1.0|     2.0|  4.0|     5.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    4.0|     6.0|     2.0|    9.0|   2.0|     2.0|     1.0|     1.0|     2.0|  888.0|     4.0|     2.0|     2.0|  2.0|     2.0|     2.0|    88.0|     2.0|     2.0|  1|\n",
      "|    4.0|    10.0|     1.0|    7.0|   2.0|     1.0|     9.0|     2.0|   103.0|  888.0|     3.0|     2.0|     1.0|  6.0|     6.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    1.0|    11.0|     1.0|    2.0|   2.0|     2.0|     9.0|     1.0|   106.0|  888.0|     2.0|     2.0|     1.0|  5.0|     4.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    2.0|    10.0|     1.0|    1.0|   2.0|     1.0|     9.0|     2.0|   103.0|  888.0|     3.0|     2.0|     1.0|  6.0|     6.0|     2.0|     1.0|     1.0|     2.0|  0|\n",
      "|    3.0|    12.0|     2.0|    7.0|   2.0|     2.0|     9.0|     1.0|   104.0|  888.0|     2.0|     2.0|     1.0|  5.0|     5.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    1.0|    13.0|     2.0|    7.0|   2.0|     1.0|     9.0|     2.0|   103.0|  205.0|     4.0|     2.0|     1.0|  6.0|     5.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    3.0|     8.0|     1.0|    1.0|   2.0|     1.0|     1.0|     1.0|   103.0|  888.0|     3.0|     2.0|     1.0|  6.0|     2.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    4.0|     6.0|     1.0|    8.0|   2.0|     1.0|     1.0|     1.0|   104.0|  888.0|     4.0|     1.0|     1.0|  5.0|     1.0|     2.0|     1.0|     1.0|     2.0|  1|\n",
      "|    3.0|    10.0|     2.0|    4.0|   2.0|     2.0|     9.0|     1.0|   103.0|  888.0|     2.0|     2.0|     1.0|  3.0|     4.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    4.0|     8.0|     2.0|    2.0|   2.0|     2.0|     1.0|     1.0|     2.0|  888.0|     4.0|     1.0|     2.0|  5.0|     2.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "|    4.0|     7.0|     1.0|    5.0|   2.0|     1.0|     1.0|     2.0|     2.0|  201.0|     4.0|     1.0|     2.0|  4.0|     2.0|     2.0|    88.0|     2.0|     2.0|  1|\n",
      "|    2.0|     9.0|     2.0|    1.0|   2.0|     2.0|     1.0|     1.0|   103.0|  888.0|     4.0|     2.0|     1.0|  4.0|     5.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    1.0|    10.0|     1.0|    2.0|   2.0|     1.0|     9.0|     1.0|   103.0|  203.0|     2.0|     2.0|     1.0|  6.0|     5.0|     2.0|    88.0|     2.0|     2.0|  0|\n",
      "|    2.0|    12.0|     2.0|    4.0|   2.0|     2.0|     9.0|     2.0|   103.0|  225.0|     3.0|     2.0|     1.0|  6.0|     9.0|     2.0|    88.0|     1.0|     2.0|  0|\n",
      "+-------+--------+--------+-------+------+--------+--------+--------+--------+-------+--------+--------+--------+-----+--------+--------+--------+--------+--------+---+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"output/processedv2.parquet\"\n",
    "\n",
    "df = spark.read.parquet(file_path)\n",
    "# df.printSchema()\n",
    "df.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GENHLTH: double (nullable = true)\n",
      " |-- _AGEG5YR: double (nullable = true)\n",
      " |-- _RFHYPE6: double (nullable = true)\n",
      " |-- EMPLOY1: double (nullable = true)\n",
      " |-- _MICHD: double (nullable = true)\n",
      " |-- _DRDXAR2: double (nullable = true)\n",
      " |-- _HCVU653: double (nullable = true)\n",
      " |-- _RFCHOL3: double (nullable = true)\n",
      " |-- METVL12_: double (nullable = true)\n",
      " |-- ALCDAY4: double (nullable = true)\n",
      " |-- _BMI5CAT: double (nullable = true)\n",
      " |-- DIFFWALK: double (nullable = true)\n",
      " |-- _TOTINDA: double (nullable = true)\n",
      " |-- EDUCA: double (nullable = true)\n",
      " |-- _INCOMG1: double (nullable = true)\n",
      " |-- CHCKDNY2: double (nullable = true)\n",
      " |-- FALL12MN: double (nullable = true)\n",
      " |-- SMOKE100: double (nullable = true)\n",
      " |-- CVDINFR4: double (nullable = true)\n",
      " |-- y: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of DataFrame: 251504 rows, 20 columns\n"
     ]
    }
   ],
   "source": [
    "num_columns = len(df.columns)\n",
    "\n",
    "num_rows = df.count()\n",
    "# Print the dimensions\n",
    "print(f\"Dimensions of DataFrame: {num_rows} rows, {num_columns} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the data into 80-20 train and test set and use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set count: 201155\n",
      "Test set count: 50349\n"
     ]
    }
   ],
   "source": [
    "df_filled = df.fillna(0)\n",
    "train_df, test_df = df_filled.randomSplit([0.8, 0.2], seed=1)\n",
    "# Show the counts of each split\n",
    "print(f\"Training set count: {train_df.count()}\")\n",
    "print(f\"Test set count: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 0.362475507154418\n",
      "Best Regularization Parameter: 0.01\n",
      "Best Elastic Net Parameter: 0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Prepare feature columns by removing the target variable 'y'\n",
    "feature_columns = df.columns\n",
    "feature_columns.remove(\"y\")\n",
    "\n",
    "# Step 1: Assemble features into a single vector for training data\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "train_data = assembler.transform(train_df)\n",
    "# Step 2: Apply PCA to reduce dimensionality\n",
    "# pca = PCA(\n",
    "#     k=10, inputCol=\"features\", outputCol=\"pca_features\"\n",
    "# )  # k is the number of principal components\n",
    "# pca_model = pca.fit(train_data)\n",
    "# train_pca = pca_model.transform(train_data)\n",
    "# Step 2: Set up Linear Regression model\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"y\")\n",
    "\n",
    "# Step 3: Set up Cross-Validation\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr.regParam, [0.1, 0.01])\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(labelCol=\"y\", metricName=\"rmse\"),\n",
    "    numFolds=5,\n",
    ")  # Use 5+ folds for cross-validation\n",
    "\n",
    "# Train the model using Cross-Validation on the training data\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Step 4: Evaluate on Test Set\n",
    "test_data = assembler.transform(test_df)\n",
    "test_predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model performance on test data\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"y\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "test_rmse = evaluator.evaluate(test_predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {test_rmse}\")\n",
    "\n",
    "# Optional: Show best model parameters from cross-validation\n",
    "best_model = cv_model.bestModel\n",
    "print(f\"Best Regularization Parameter: {best_model._java_obj.getRegParam()}\")\n",
    "print(f\"Best Elastic Net Parameter: {best_model._java_obj.getElasticNetParam()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
