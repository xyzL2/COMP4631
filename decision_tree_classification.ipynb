{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame (df) should be loaded/defined before the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "# Define feature columns (excluding the label column 'y')\n",
    "feature_columns = [\n",
    "    \"GENHLTH\", \"_AGEG5YR\", \"_RFHYPE6\", \"EMPLOY1\",\n",
    "    \"_MICHD\", \"_DRDXAR2\", \"_HCVU653\", \"_RFCHOL3\", \"METVL12_\", \n",
    "    \"ALCDAY4\", \"_BMI5CAT\", \"DIFFWALK\", \n",
    "    \"_TOTINDA\", \"EDUCA\", \"_INCOMG1\", \"CHCKDNY2\", \"FALL12MN\", \"SMOKE100\", \"CVDINFR4\"\n",
    "]\n",
    "\n",
    "\n",
    "# Assemble feature columns into a feature vector\n",
    "vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data_with_features = vector_assembler.transform(df)\n",
    "\n",
    "# Select the relevant columns for modeling\n",
    "data_for_model = data_with_features.select(\"features\", \"y\")\n",
    "\n",
    "# Split the Data into 80% Training, 20% Testing\n",
    "train_validation_data, test_data = data_for_model.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "\n",
    "# Train the Decision Tree with Hyperparameter Tuning\n",
    "decision_tree = DecisionTreeClassifier(labelCol=\"y\", featuresCol=\"features\")\n",
    "\n",
    "# Create a ParamGridBuilder to tune hyperparameters\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(decision_tree.maxDepth, [5, 6, 7, 8])  # Hyperparameters to tune\n",
    "              .addGrid(decision_tree.minInstancesPerNode, [1, 2, 3])  # Tuning another hyperparameter\n",
    "              .build())\n",
    "\n",
    "# Create the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"y\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Set up cross-validation\n",
    "cross_validator = CrossValidator(estimator=decision_tree, \n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=evaluator, \n",
    "                                 numFolds=3)  # 3-fold cross-validation\n",
    "\n",
    "# Fit the model using Cross-Validation on the combined Training + Validation Data\n",
    "cv_model = cross_validator.fit(train_validation_data)\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the Model on Test Data\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display the decision tree structure\n",
    "print(cv_model.bestModel.toDebugString)\n",
    "\n",
    "# Group predictions by the predicted class\n",
    "predictions.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of decision tree\n",
    "\n",
    "# Get feature importances from the best model found by cross-validation\n",
    "importances = cv_model.bestModel.featureImportances\n",
    "\n",
    "# Map feature importances to the feature names\n",
    "feature_importance = [(name, importance) for name, importance in zip(feature_columns, importances)]\n",
    "sorted_features = sorted(feature_importance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted features by importance\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in sorted_features:\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
